__author__ = "Andrei Guliaev"
__copyright__ = "Copyright 2025, Andrei Guliaev"
__email__ = "andrei.guliaev@scilifelab.uu.se"
__license__ = "GPL-3"


# Include pipeline specific rules
include: "rules/common.smk"


# 'All' rule, must be specified before any other modules are
# included, since they also contain 'All' rule
rule all:
    input:
        compile_output_file_list,


# map and index BAM files
module alignment:
    snakefile:
        github(
            "hydra-genetics/alignment",
            path="workflow/Snakefile",
            branch="develop",
        )
    config:
        config


module annotation:
    snakefile:
        github(
            "hydra-genetics/annotation",
            path="workflow/Snakefile",
            branch="develop",
        )
    config:
        config


module cnv_sv:
    snakefile:
        github(
            "hydra-genetics/cnv_sv",
            path="workflow/Snakefile",
            branch="haplotag_get_input_bam",
        )
    config:
        config


# filter VCF files
module filtering:
    snakefile:
        github(
            "hydra-genetics/filtering",
            path="workflow/Snakefile",
            branch="develop",
        )
    config:
        config


# mark duplicates in CCS reads
module prealignment:
    snakefile:
        github(
            "hydra-genetics/prealignment",
            path="workflow/Snakefile",
            branch="develop",
        )
    config:
        config


# CNVkit reports
module reports:
    snakefile:
        github(
            "hydra-genetics/reports",
            path="workflow/Snakefile",
            branch="develop",
        )
    config:
        config


# use branch with my function
# for flexible BAM input
module snv_indels:
    snakefile:
        github(
            "hydra-genetics/snv_indels",
            path="workflow/Snakefile",
            branch="deepsomatic_flexible_input",
        )
    config:
        config


# for depth of coverage
module qc:
    snakefile:
        github(
            "hydra-genetics/qc",
            path="workflow/Snakefile",
            branch="develop",
        )
    config:
        config


# MAPPING
use rule pbmarkdup from prealignment as prealignment_pbmarkdup


use rule pbmm2_index from alignment as alignment_pbmm2_index


use rule pbmm2_align from alignment as alignment_pbmm2_align with:
    input:
        query="prealignment/pbmarkdup/{sample}_{type}_{processing_unit}_{barcode}.bam",
        reference=expand(
            "alignment/pbmm2_index/{ref}.{preset}.mmi",
            ref=os.path.basename(config.get("reference", {}).get("fasta", "")),
            preset=config.get("pbmm2_align", {}).get("preset", ""),
        ),


use rule pbmm2_merge from alignment as alignment_pbmm2_merge


use rule samtools_index from alignment as alignment_samtools_index_whatshap with:
    wildcard_constraints:
        file="^annotation/whatshap_haplotag/.+",


use rule samtools_index from alignment as alignment_samtools_index_pbmm2 with:
    wildcard_constraints:
        file="^alignment/pbmm2_align/.+",


# SNV & INDELS
use rule deepsomatic_t_only from snv_indels as snv_indels_deepsomatic_t_only with:
    input:
        bam="alignment/pbmm2_align/{sample}_T.bam",
        bai="alignment/pbmm2_align/{sample}_T.bam.bai",
        ref=config.get("reference", {}).get("fasta", ""),
        bed=config.get("reference", {}).get("design_bed", ""),
        pon=config.get("deepsomatic_t_only", {}).get("pon", ""),
    output:
        tmpdir=temp(directory("snv_indels/deepsomatic_t_only/{sample}.tmp")),
        vcf="snv_indels/deepsomatic_t_only/{sample}_T.vcf.gz",


use rule whatshap_phase from annotation as annotation_whatshap_phase


use rule tabix from cnv_sv as cnv_sv_tabix with:
    wildcard_constraints:
        file="^annotation/whatshap_phase/.+",


use rule bcftools_filter_include_region from filtering as filtering_bcftools_filter_include_region with:
    wildcard_constraints:
        file="^annotation/whatshap_phase/.+",


use rule whatshap_haplotag from annotation as annotation_whatshap_haplotag


# STRUCTURAL VARIANTS
# run PBSV & HiFiCNV analysis
use rule pbsv_discover from cnv_sv as cnv_sv_pbsv_discover


use rule pbsv_call from cnv_sv as cnv_sv_pbsv_call


# bgzip PBSV VCF
# required for filtering
use rule bgzip from cnv_sv as cnv_sv_bgzip with:
    input:
        vcf="{file}_T.vcf",
    output:
        "{file}_T.vcf.gz",


# index PBSV VCF
# required for filtering
use rule tabix from cnv_sv as cnv_sv_tabix_pbsv with:
    wildcard_constraints:
        file="^cnv_sv/.+",


use rule hificnv from cnv_sv as cnv_sv_hificnv


# run Sniffles2
use rule sniffles2_call from cnv_sv as cnv_sv_sniffles2


# run CNVkit
use rule cnvkit_batch from cnv_sv as cnv_sv_cnvkit_batch with:
    output:
        antitarget_coverage=temp("cnv_sv/cnvkit_batch/{sample}/{sample}_{type}.haplotagged.antitargetcoverage.cnn"),
        bins=temp("cnv_sv/cnvkit_batch/{sample}/{sample}_{type}.haplotagged.bintest.cns"),
        regions=temp("cnv_sv/cnvkit_batch/{sample}/{sample}_{type}.haplotagged.cnr"),
        segments=temp("cnv_sv/cnvkit_batch/{sample}/{sample}_{type}.haplotagged.cns"),
        segments_called=temp("cnv_sv/cnvkit_batch/{sample}/{sample}_{type}.haplotagged.call.cns"),
        target_coverage=temp("cnv_sv/cnvkit_batch/{sample}/{sample}_{type}.haplotagged.targetcoverage.cnn"),

# to create 'germline' vcf from gnomAD
# it annotaes your vcf with gnomad frequencies
# which you can then use to filter out (or  keep!) some variants
# use svn_indels VCF as input to VEP
# cause that's how it is in the original cnvkit_call
use rule tabix from cnv_sv as cnv_sv_tabix_deepsomatic with:
    wildcard_constraints:
        file="snv_indels/deepsomatic_t_only/.+"

use rule vep from annotation as annotation_vep with:
    wildcard_constraints:
        file="snv_indels/deepsomatic_t_only/.+"

# vep output has to be bgzipped and indexed
use rule bgzip from cnv_sv as bgzip_vep_vcf with:
    wildcard_constraints:
        file="snv_indels/deepsomatic_t_only/.+"

# use rule tabix from cnv_sv as tabix_vep_vcf with:
#     wildcard_constraints:
#         file="snv_indels/deepsomatic_t_only/.+_T.vep_annotated.vcf.gz"
    
# now you can filter it (keep the populational variants)
use rule filter_vcf from filtering as filtering_filter_vcf with:
    wildcard_constraints:
        file="snv_indels/deepsomatic_t_only/.+"


# outputs loh.cns file
use rule cnvkit_call from cnv_sv as cnv_sv_cnvkit_call with:
    input:
        segment="cnv_sv/cnvkit_batch/{sample}/{sample}_{type}.haplotagged.cns",
        vcf="snv_indels/deepsomatic_t_only/{sample}_{type}.vep_annotated.filter.germline.vcf"

# this one takes the loh file
use rule cnvkit_vcf from cnv_sv as cnv_sv_cnvkit_vcf with:
    input:
        segment="snv_indels/deepsomatic_t_only/{sample}_{type}.vep_annotated.filter.germline.vcf"


use rule annotate_cnv from annotation as annotation_annotate_cnv



# CNVkit reports
use rule cnv_json from reports as reports_cnv_json with:
    input:
        ratios=get_cnv_ratios,
        segments=get_cnv_segments,


# this one has filtered_cnv_vcfs, cnv_vcfs, germline_vcf as input
# they are clearly omitted here
#
use rule merge_cnv_json from reports as reports_merge_cnv_json


use rule cnv_html_report from reports as reports_cnv_html_report with:
    input:
        json="reports/cnv_html_report/{sample}_{type}.{tc_method}.merged.json",
        html_template="workflow/templates/cnv_html_report/index.html",
        js_files=[
            "workflow/templates/assets/js/d3.v7.min.js",
            "workflow/templates/cnv_html_report/01-chromosome-plot.js",
            "workflow/templates/cnv_html_report/02-genome-plot.js",
            "workflow/templates/cnv_html_report/03-results-table.js",
            "workflow/templates/cnv_html_report/04-window-summary.js",
            "workflow/templates/cnv_html_report/05-main.js",
        ],
        css_files=["workflow/templates/assets/css/icons.css", "workflow/templates/cnv_html_report/style.css"],
        tc_file=get_tc_file,
        extra_table_files=[t["path"] for t in config.get("cnv_html_report", {}).get("extra_tables", [])],


# depth of coverage
use rule mosdepth_bed from qc as qc_mosdepth_bed with:
    input:
        bam="annotation/whatshap_haplotag/{sample}_T.haplotagged.bam",
        bai="annotation/whatshap_haplotag/{sample}_T.haplotagged.bam.bai",
        bed=config.get("reference", {}).get("targets_bed", ""),
