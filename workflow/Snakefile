__author__ = "Andrei Guliaev"
__copyright__ = "Copyright 2025, Andrei Guliaev"
__email__ = "andrei.guliaev@scilifelab.uu.se"
__license__ = "GPL-3"


# Include pipeline specific rules
include: "rules/common.smk"


# 'All' rule, must be specified before any other modules are
# included, since they also contain 'All' rule
rule all:
    input:
        compile_output_file_list,


# map and index BAM files
module alignment:
    snakefile:
        github(
            "hydra-genetics/alignment",
            path="workflow/Snakefile",
            branch="develop",
        )
    config:
        config


module annotation:
    snakefile:
        github(
            "hydra-genetics/annotation",
            path="workflow/Snakefile",
            branch="develop",
        )
    config:
        config


module cnv_sv:
    snakefile:
        github(
            "hydra-genetics/cnv_sv",
            path="workflow/Snakefile",
            branch="develop",
        )
    config:
        config


# filter VCF files
module filtering:
    snakefile:
        github(
            "hydra-genetics/filtering",
            path="workflow/Snakefile",
            branch="develop",
        )
    config:
        config


# mark duplicates in CCS reads
module prealignment:
    snakefile:
        github(
            "hydra-genetics/prealignment",
            path="workflow/Snakefile",
            branch="develop",
        )
    config:
        config


# CNVkit reports
module reports:
    snakefile:
        github(
            "hydra-genetics/reports",
            path="workflow/Snakefile",
            branch="develop",
        )
    config:
        config


# use branch with my function
# for flexible BAM input
module snv_indels:
    snakefile:
        github(
            "hydra-genetics/snv_indels",
            path="workflow/Snakefile",
            branch="develop",
        )
    config:
        config


# for depth of coverage
module qc:
    snakefile:
        github(
            "hydra-genetics/qc",
            path="workflow/Snakefile",
            branch="develop",
        )
    config:
        config


# MAPPING
use rule pbmarkdup from prealignment as prealignment_pbmarkdup


use rule pbmm2_index from alignment as alignment_pbmm2_index


use rule pbmm2_align from alignment as alignment_pbmm2_align with:
    input:
        query="prealignment/pbmarkdup/{sample}_{type}_{processing_unit}_{barcode}.bam",
        reference=expand(
            "alignment/pbmm2_index/{ref}.{preset}.mmi",
            ref=os.path.basename(config.get("reference", {}).get("fasta", "")),
            preset=config.get("pbmm2_align", {}).get("preset", ""),
        ),


use rule pbmm2_merge from alignment as alignment_pbmm2_merge


use rule samtools_index from alignment as alignment_samtools_index_haplotagged_bam with:
    wildcard_constraints:
        file="^snv_indels/whatshap_haplotag/.+",


use rule samtools_index from alignment as alignment_samtools_index_pbmm2 with:
    wildcard_constraints:
        file="^alignment/pbmm2_align/.+",


# SNV & INDELS
use rule clairs_to_call from snv_indels as snv_indels_clairs_to_call with:
    input:
        bam="alignment/pbmm2_align/{sample}_T.bam",
        bai="alignment/pbmm2_align/{sample}_T.bam.bai",
        ref=config.get("reference", {}).get("fasta", ""),
        bed=config.get("reference", {}).get("design_bed", ""),

use rule clairs_to_concat from snv_indels as snv_indels_clairs_to_concat with:
    output:
        vcf="snv_indels/clairs_to/{sample}_{type}.vcf.gz",

# Phase ClairS-TO output only
use rule whatshap_phase from snv_indels as snv_indels_whatshap_phase_clairs with:
    input:
        vcf="snv_indels/clairs_to/{sample}_T.vcf.gz",
        bai="alignment/pbmm2_align/{sample}_T.bam.bai",
        bam="alignment/pbmm2_align/{sample}_T.bam",
        fasta=config.get("reference", {}).get("fasta", ""),
    output:
        vcf=temp("snv_indels/whatshap_phase/{sample}_T.clairs.phased.vcf.gz"),
    params:
        extra=config.get("whatshap_phase", {}).get("extra", ""),
    log:
        "snv_indels/whatshap_phase/{sample}_T.clairs.phased.vcf.gz.log",
    benchmark:
        repeat(
            "snv_indels/whatshap_phase/{sample}_T.clairs.phased.vcf.gz.benchmark.tsv",
            config.get("whatshap_phase", {}).get("benchmark_repeats", 1),
        )

# index the phased vcf from clairs
use rule tabix from cnv_sv as cnv_sv_tabix_clairs with:
    wildcard_constraints:
        file="^snv_indels/whatshap_phase/.+\.clairs\.phased",


use rule bcftools_filter_include_region from filtering as filtering_bcftools_filter_include_region_clairs with:
    wildcard_constraints:
        file="^snv_indels/whatshap_phase/.+\.clairs\.phased",


use rule whatshap_haplotag from snv_indels as snv_indels_whatshap_haplotag with:
    input:
        aln=lambda wildcards: get_input_bam(wildcards)[0],
        bai=lambda wildcards: get_input_bam(wildcards)[1],
        ref=config.get("reference", {}).get("fasta", ""),
        fai=config.get("reference", {}).get("fai", ""),
        vcf="snv_indels/whatshap_phase/{sample}_{type}.clairs.phased.vcf.gz",
        tbi="snv_indels/whatshap_phase/{sample}_{type}.clairs.phased.vcf.gz.tbi",

# SNV & INDELS from DeepSomatic-TO
# use custom PoN from config
# post-calling filtering by regions BED is not needed here
use rule deepsomatic_t_only from snv_indels as snv_indels_deepsomatic_t_only with:
    wildcard_constraints:
        type="T",
# output snv_indels/deepsomatic_t_only/{sample}_{type}.vcf.gz

# Pahse DeepSomatic-TO output
use rule whatshap_phase from snv_indels as snv_indels_whatshap_phase_deepsomatic with:
    input:
        vcf="snv_indels/deepsomatic_t_only/{sample}_T.vcf.gz",
        bai="alignment/pbmm2_align/{sample}_T.bam.bai",
        bam="alignment/pbmm2_align/{sample}_T.bam",
        fasta=config.get("reference", {}).get("fasta", ""),
    output:
        vcf=temp("snv_indels/whatshap_phase/{sample}_T.deepsomatic.phased.vcf.gz"),
    params:
        extra=config.get("whatshap_phase", {}).get("extra", ""),
    log:
        "snv_indels/whatshap_phase/{sample}_T.deepsomatic.phased.vcf.gz.log",
    benchmark:
        repeat(
            "snv_indels/whatshap_phase/{sample}_T.deepsomatic.phased.vcf.gz.benchmark.tsv",
            config.get("whatshap_phase", {}).get("benchmark_repeats", 1),
        )


# index the phased vcf from deepsomatic
use rule tabix from cnv_sv as cnv_sv_tabix_deepsomatic with:
    wildcard_constraints:
        file="^snv_indels/whatshap_phase/.+\.deepsomatic\.phased",



# STRUCTURAL VARIANTS
# run PBSV & HiFiCNV analysis
use rule pbsv_discover from cnv_sv as cnv_sv_pbsv_discover


use rule pbsv_call from cnv_sv as cnv_sv_pbsv_call


# bgzip PBSV VCF
# required for filtering
use rule bgzip from cnv_sv as cnv_sv_bgzip with:
    input:
        vcf="{file}_T.vcf",
    output:
        "{file}_T.vcf.gz",
    wildcard_constraints:
        file="^cnv_sv/pbsv_call/.+",


# index PBSV VCF
# required for filtering
use rule tabix from cnv_sv as cnv_sv_tabix_pbsv with:
    wildcard_constraints:
        file="^cnv_sv/pbsv_call/.+",


use rule hificnv from cnv_sv as cnv_sv_hificnv


# run Sniffles2
use rule sniffles2_call from cnv_sv as cnv_sv_sniffles2


# run CNVkit
#use rule cnvkit_batch from cnv_sv as cnv_sv_cnvkit_batch with:
rule cnv_sv_cnvkit_batch_local:
    input:
        bam=["snv_indels/whatshap_haplotag/{sample}_{type}.haplotagged.bam"],
        bai=["snv_indels/whatshap_haplotag/{sample}_{type}.haplotagged.bam.bai"],
        #reference=config.get("cnvkit_batch", {}).get("normal_reference", ""),
        reference="../build_pon/results/cnvkit_build_normal_reference/cnvkit.PoN.cnn",
    output:
        antitarget_coverage=temp("cnv_sv/cnvkit_batch/{sample}/{sample}_{type}.haplotagged.antitargetcoverage.cnn"),
        bins=temp("cnv_sv/cnvkit_batch/{sample}/{sample}_{type}.haplotagged.bintest.cns"),
        regions=temp("cnv_sv/cnvkit_batch/{sample}/{sample}_{type}.haplotagged.cnr"),
        segments=temp("cnv_sv/cnvkit_batch/{sample}/{sample}_{type}.haplotagged.cns"),
        segments_called=temp("cnv_sv/cnvkit_batch/{sample}/{sample}_{type}.haplotagged.call.cns"),
        target_coverage=temp("cnv_sv/cnvkit_batch/{sample}/{sample}_{type}.haplotagged.targetcoverage.cnn"),
    params:
        extra=config.get("cnvkit_batch", {}).get("extra", ""),
        method=config.get("cnvkit_batch", {}).get("method", "hybrid"),
    log:
        "cnv_sv/cnvkit_batch/{sample}/{sample}_{type}.call.cns.log",
    benchmark:
        repeat(
            "cnv_sv/cnvkit_batch/{sample}/{sample}_{type}.call.cns.benchmark.tsv",
            config.get("cnvkit_batch", {}).get("benchmark_repeats", 1),
        )
    threads: config.get("cnvkit_batch", {}).get("threads", config["default_resources"]["threads"])
    resources:
        mem_mb=config.get("cnvkit_batch", {}).get("mem_mb", config["default_resources"]["mem_mb"]),
        mem_per_cpu=config.get("cnvkit_batch", {}).get("mem_per_cpu", config["default_resources"]["mem_per_cpu"]),
        partition=config.get("cnvkit_batch", {}).get("partition", config["default_resources"]["partition"]),
        threads=config.get("cnvkit_batch", {}).get("threads", config["default_resources"]["threads"]),
        time=config.get("cnvkit_batch", {}).get("time", config["default_resources"]["time"]),
    container:
        config.get("cnvkit_batch", {}).get("container", config["default_container"])
    message:
        "{rule}: use cnvkit to call cnvs in {wildcards.sample}/{wildcards.sample}_{wildcards.type}"
    script:
        "scripts/cnvkit_batch_script.py"


# to create 'germline' vcf from gnomAD
# it annotates your vcf with gnomad frequencies
# which you can then use to filter out (or  keep!) some variants
# use svn_indels VCF as input to VEP
# cause that's how it is in the original cnvkit_call

# index phased.inlcude.panel.vcf
use rule tabix from cnv_sv as cnv_sv_tabix_include_panel with:
    wildcard_constraints:
        file="^snv_indels/whatshap_phase/.+\.clairs\.phased\.include\.panel",

use rule vep from annotation as annotation_vep_clairs with:
    wildcard_constraints:
        file="snv_indels/whatshap_phase/.+\.clairs\.phased\.include\.panel",


# vep output has to be bgzipped and indexed
use rule bgzip from cnv_sv as bgzip_vep_vcf with:
    wildcard_constraints:
        file="snv_indels/whatshap_phase/.+",
    input:
        vcf="{file}_T.clairs.phased.include.panel.vep_annotated.vcf",
    output:
        gz="{file}_T.clairs.phased.include.panel.vep_annotated.vcf.gz",


use rule tabix from cnv_sv as tabix_vep_vcf with:
    wildcard_constraints:
        file="snv_indels/whatshap_phase/.+_T\.clairs\.phased\.include\.panel\.vep_annotated",


# now you can filter it (keep the populational variants)
use rule filter_vcf from filtering as filtering_filter_vep_annotated_vcf with:
    wildcard_constraints:
        file="snv_indels/whatshap_phase/.+\.clairs\.phased\.include\.panel\.vep_annotated",

# fix AF entries
rule fix_af:
    input:
        vcf="snv_indels/whatshap_phase/{sample}_{type}.clairs.phased.include.panel.vep_annotated.filter.germline.vcf",
    output:
        vcf=temp("snv_indels/whatshap_phase/{sample}_{type}.clairs.phased.include.panel.vep_annotated.filter.germline.fix_af.vcf"),
    log:
        "snv_indels/whatshap_phase/{sample}_{type}.fix_af.vcf.log",
    benchmark:
        repeat(
            "snv_indels/whatshap_phase/{sample}_{type}.fix_af.vcf.benchmark.tsv",
            config.get("fix_af", {}).get("benchmark_repeats", 1),
        )
    threads: config.get("fix_af", {}).get("threads", config["default_resources"]["threads"])
    resources:
        mem_mb=config.get("fix_af", {}).get("mem_mb", config["default_resources"]["mem_mb"]),
        mem_per_cpu=config.get("fix_af", {}).get("mem_per_cpu", config["default_resources"]["mem_per_cpu"]),
        partition=config.get("fix_af", {}).get("partition", config["default_resources"]["partition"]),
        threads=config.get("fix_af", {}).get("threads", config["default_resources"]["threads"]),
        time=config.get("fix_af", {}).get("time", config["default_resources"]["time"]),
    container:
        config.get("fix_af", {}).get("container", config["default_container"])
    message:
        "{rule}: fix missing allele frequency field in format column in {input.vcf}"
    script:
        "scripts/fix_af.py"

# outputs loh.cns file
# use rule cnvkit_call from cnv_sv as cnv_sv_cnvkit_call with:
#     input:
#         segment="cnv_sv/cnvkit_batch/{sample}/{sample}_{type}.haplotagged.cns",
#         vcf="snv_indels/deepsomatic_t_only/{sample}_{type}.vep_annotated.filter.germline.vcf"


rule cnvkit_call_new_wrapper:
    wildcard_constraints:
        tc_method="pathology"
    input:
        segment="cnv_sv/cnvkit_batch/{sample}/{sample}_{type}.haplotagged.cns",
        vcf="snv_indels/whatshap_phase/{sample}_{type}.clairs.phased.include.panel.vep_annotated.filter.germline.vcf",
        tc_file=get_tc_file,
    output:
        segment=temp("cnv_sv/cnvkit_call/{sample}_{type}.{tc_method}.loh.cns"),
    params:
        extra=config.get("cnvkit_call", {}).get("extra", ""),
        purity=0.9,
    log:
        "cnv_sv/cnvkit_call/{sample}_{type}.{tc_method}.loh.cns.log",
    benchmark:
        repeat(
            "cnv_sv/cnvkit_call/{sample}_{type}.{tc_method}.loh.cns.benchmark.tsv",
            config.get("cnvkit_call", {}).get("benchmark_repeats", 1),
        )
    threads: config.get("cnvkit_call", {}).get("threads", config["default_resources"]["threads"])
    resources:
        mem_mb=config.get("cnvkit_call", {}).get("mem_mb", config["default_resources"]["mem_mb"]),
        mem_per_cpu=config.get("cnvkit_call", {}).get("mem_per_cpu", config["default_resources"]["mem_per_cpu"]),
        partition=config.get("cnvkit_call", {}).get("partition", config["default_resources"]["partition"]),
        threads=config.get("cnvkit_call", {}).get("threads", config["default_resources"]["threads"]),
        time=config.get("cnvkit_call", {}).get("time", config["default_resources"]["time"]),
    container:
        config.get("cnvkit_call", {}).get("container", config["default_container"])
    message:
        "{rule}: call cnvs with loh info into cnv_sv/cnvkit_call/{wildcards.sample}_{wildcards.type}.loh.cns"
    script:
        "scripts/cnvkit_call.py"


# this one takes the loh file from cnvkit_call
use rule cnvkit_vcf from cnv_sv as cnv_sv_cnvkit_vcf with:
    wildcard_constraints:
        tc_method="pathology"
# output: vcf=temp("cnv_sv/cnvkit_vcf/{sample}_{type}.{tc_method}.vcf"),

# bgzip and index this pathology.vcf file
# use rule bgzip from cnv_sv as cnv_sv_bgzip_cnvkit_vcf_pathology with:
#     wildcard_constraints:
#         file="cnv_sv/cnvkit_vcf/.+\.pathology",

# use rule tabix from cnv_sv as cnv_sv_tabix_cnvkit_vcf_pathology with:
#     wildcard_constraints:
#         file="cnv_sv/cnvkit_vcf/.+\.pathology",

use rule annotate_cnv from annotation as annotation_annotate_cnvkit_vcf with:
    input:
        vcf="cnv_sv/cnvkit_vcf/{sample}_T.pathology.vcf"
    output:
        vcf="cnv_sv/cnvkit_vcf/{sample}_T.pathology.annotate_cnv.{tag}.vcf",
    params:
        bed=lambda wildcards: config.get("annotate_cnv", {}).get(wildcards.tag, ""),
    log:
        "cnv_sv/cnvkit_vcf/{sample}_T.pathology.annotate_cnv.{tag}.vcf.log",
    benchmark:
        repeat(
            "cnv_sv/cnvkit_vcf/{sample}_T.pathology.annotate_cnv.{tag}.vcf.benchmark.tsv",
            config.get("annotate_cnv", {}).get("benchmark_repeats", 1),
        )

# one more round of bgzip+tabix
use rule bgzip from cnv_sv as cnv_sv_bgzip_cnvkit_vcf with:
    wildcard_constraints:
        file="cnv_sv/cnvkit_vcf/.+\.pathology\.annotate_cnv\.germline",

use rule tabix from cnv_sv as cnv_sv_tabix_cnvkit_vcf with:
    wildcard_constraints:
        file="cnv_sv/cnvkit_vcf/.+\.pathology\.annotate_cnv\.germline",

# CNVkit reports
# the inputs here are cns and cnr files from cnvkit_batch
# t.ex.: "cnv_sv/cnvkit_batch/{sample}/{sample}_{type}.cns"
use rule cnv_json from reports as reports_cnv_json with:
    wildcard_constraints:
        tc_method="pathology",
        caller="cnvkit"
    input:
        ratios="cnv_sv/cnvkit_batch/{sample}/{sample}_{type}.haplotagged.cnr",
        segments="cnv_sv/cnvkit_batch/{sample}/{sample}_{type}.haplotagged.cns",
# output: json=temp("reports/cnv_html_report/{sample}_{type}.{caller}.{tc_method}.json"),

# this one has filtered_cnv_vcfs, cnv_vcfs, germline_vcf as input

# ["reports/cnv_html_report/{sample}_{type}.{caller}.{tc_method}.json".format(caller=c, **wildcards) for c in callers]
use rule merge_cnv_json from reports as reports_merge_cnv_json
# output: "reports/cnv_html_report/{sample}_{type}.{tc_method}.merged.json"


use rule cnv_html_report from reports as reports_cnv_html_report with:
    input:
        json="reports/cnv_html_report/{sample}_{type}.{tc_method}.merged.json",
        html_template="workflow/templates/cnv_html_report/index.html",
        js_files=[
            "workflow/templates/assets/js/d3.v7.min.js",
            "workflow/templates/cnv_html_report/01-chromosome-plot.js",
            "workflow/templates/cnv_html_report/02-genome-plot.js",
            "workflow/templates/cnv_html_report/03-results-table.js",
            "workflow/templates/cnv_html_report/04-window-summary.js",
            "workflow/templates/cnv_html_report/05-main.js",
        ],
        css_files=["workflow/templates/assets/css/icons.css", "workflow/templates/cnv_html_report/style.css"],
        tc_file=get_tc_file,
        extra_table_files=[t["path"] for t in config.get("cnv_html_report", {}).get("extra_tables", [])],


# depth of coverage
use rule mosdepth_bed from qc as qc_mosdepth_bed with:
    input:
        bam="annotation/whatshap_haplotag/{sample}_T.haplotagged.bam",
        bai="annotation/whatshap_haplotag/{sample}_T.haplotagged.bam.bai",
        bed=config.get("reference", {}).get("targets_bed", ""),
